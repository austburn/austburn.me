<p>This post will be dedicated to getting <a class="content-link" href="https://www.elastic.co/products/elasticsearch">Elasticsearch</a> setup. I will outline the general setup, different broadcast protocols and some problems that I ran into while getting the cluster setup.</p>
<p class="tip"><strong>Note:</strong> Setup was performed on 1 GB General Purpose v1 Ubuntu 14.04 LTS servers on the <a class="content-link" href="https://mycloud.rackspace.com">Rackspace Cloud</a>.</p>
<h2>Setting up Elasticsearch</h2>
<ol>
  <li>Install Java 8.</li>
      <pre><code class="custom-bash">
$ sudo apt-add-repository ppa:webupd8team/java
$ sudo apt-get update
$ sudo apt-get install oracle-java8-installer
  </code></pre>
  <p>Via <a class="content-link" href="http://askubuntu.com/questions/521145/how-to-install-oracle-java-on-ubuntu-14-04">AskUbuntu</a>.</p>
  <li>Create a user for Elasticsearch. As of <code><a class="content-link" href="https://www.elastic.co/guide/en/elasticsearch/reference/2.1/release-notes-2.0.0-beta1.html">elasticsearch-2.x.x</a></code>, <code>elasticsearch</code> can no longer be run as <code>root</code>.</li>
      <pre><code class="custom-bash">
$ adduser elastic
# enter password, etc.
$ sudo adduser elastic sudo # if we do this now, we can take care of the iptables rules later without switching users
$ cd ~ # go to elastic home directory
  </code></pre>
  <li>Fetch <code>elasticsearch</code> and untar it.</li>
      <pre><code class="custom-bash">
$ wget https://download.elasticsearch.org/elasticsearch/release/org/elasticsearch/distribution/tar/elasticsearch/2.1.0/elasticsearch-2.1.0.tar.gz
$ tar xzf elasticsearch-2.1.0.tar.gz
$ cd elasticsearch-2.1.0
  </code></pre>
  <p class="tip"><strong>Note:</strong> I used <code>elasticsearch-2.1.0</code> for the remainder of the blog post. This has cascading effects which I will discuss below.</p>
  <li>Run <code>elasticsearch</code>.</li>
      <pre><code class="custom-bash">
$ bin/elasticsearch
[2015-11-30 20:27:05,128][INFO ][node                     ] [Her] initializing ...
[2015-11-30 20:27:08,730][INFO ][node                     ] [Her] initialized
[2015-11-30 20:27:08,733][INFO ][node                     ] [Her] starting ...
[2015-11-30 20:27:09,006][INFO ][transport                ] [Her] publish_address {127.0.0.1:9300}, bound_addresses {127.0.0.1:9300}, {[::1]:9300}
[2015-11-30 20:27:09,041][INFO ][discovery                ] [Her] elasticsearch/k42QuVacTlmyz6HkmjDOoA
[2015-11-30 20:27:12,146][INFO ][cluster.service          ] [Her] new_master {Her}{k42QuVacTlmyz6HkmjDOoA}{127.0.0.1}{127.0.0.1:9300}, reason: zen-disco-join(elected_as_master, [0] joins received)
[2015-11-30 20:27:12,190][INFO ][http                     ] [Her] publish_address {127.0.0.1:9200}, bound_addresses {127.0.0.1:9200}, {[::1]:9200}
[2015-11-30 20:27:12,193][INFO ][node                     ] [Her] started
  </code></pre>
  <p>There will be some other logs mixed in here, but this is the gist. Here, <code>Her</code> is a random node name and <code>elasticsearch</code> is the default cluster name. It binds to the local interface on port <code>9300</code> for the transport module and <code>9200</code> for the http module by default (which we'll discuss later). Additionally, it elects itself as master because it did not detect any other running instances of <code>elasticsearch</code>.</p>
</ol>
<h2>Networking</h2>
<h3>Unicast</h3>
<p>I will start by showing you how to configure your nodes to communicate via the unicast protocol first. As of <code><a class="content-link" href="https://www.elastic.co/guide/en/elasticsearch/reference/2.1/release-notes-2.0.0-beta1.html">elasticsearch-2.0.0</a></code>, <a class="content-link" href="https://github.com/elastic/elasticsearch/pull/12999">unicast discovery</a> is now the default.</p>
<p>If you look inside <code>~/elasticsearch-2.1.0/config/</code>, you will see a file named <code>elasticsearch.yml</code>. By default, everything in this file is commented out. We'll now edit the configuration to enable these nodes to communicate with eachother via unicast.</p>
<ol>
  <li>Setup the configuration file.</li>
      <pre><code class="yaml">
# This value will be the same across all instances of elasticsearch
cluster.name: irc
# This value is unique per instances
node.name: node-1
# The interface you want elasticsearch to communicate over, I used the public interface
network.host: 123.456.789.100
# A list of other node's host:port running elasticsearch
discovery.zen.ping.unicast.hosts: ["456.789.101.234:9300", "789.101.234.567:9300"]
  </code></pre>
  <p class="tip"><strong>Note:</strong> <code>9300</code> is the default port that the transport module communicates over. <code>9200</code> is the default port for the http module that provides the <a class="content-link" href="https://www.elastic.co/guide/en/elasticsearch/reference/2.1/cat.html">elasticsearch API</a>.</p>
  <li>Be sure to open up ports via <code>iptables</code>.</li>
      <pre><code class="custom-bash">
sudo iptables -A INPUT -i eth0 -p tcp --dport 9300 -m state --state NEW,ESTABLISHED -j ACCEPT
sudo iptables -A OUTPUT -o eth0 -p tcp --sport 9300 -m state --state ESTABLISHED -j ACCEPT
  </code></pre>
  <p class="tip">These rules will open communication over port <code>9300</code> on the public interface (<code>eth0</code>).</p>
  <li>Repeat steps 1 and 2 for all nodes in your cluser. Make sure to change the <code>node.name</code> and <code>discovery.zen.ping.unicast.hosts</code> accordingly.</li>
  <li>Start up your <code>elasticsearch</code> instances.</li>
      <pre><code class="custom-bash">
elastic@node-1 $ cd ~/elasticsearch-2.1.0
elastic@node-1 $ bin/elasticsearch
[2015-12-02 21:56:40,260][INFO ][node                     ] [node-1] initializing ...
[2015-12-02 21:56:43,691][INFO ][node                     ] [node-1] initialized
[2015-12-02 21:56:43,693][INFO ][node                     ] [node-1] starting ...
[2015-12-02 21:56:43,952][INFO ][transport                ] [node-1] publish_address {xxx.xx.xx.xx:9300}, bound_addresses {xxx.xx.xx.xx:9300}
[2015-12-02 21:56:43,992][INFO ][discovery                ] [node-1] irc/dg72ivnNTxCD6K3co6tslw
[2015-12-02 21:56:47,042][INFO ][cluster.service          ] [node-1] new_master {node-1}{dg72ivnNTxCD6K3co6tslw}{xxx.xx.xx.xx}{xxx.xx.xx.xx:9300}, reason: zen-disco-join(elected_as_master, [0] joins received)
[2015-12-02 21:56:47,074][INFO ][http                     ] [node-1] publish_address {xxx.xx.xx.xx:9200}, bound_addresses {xxx.xx.xx.xx:9200}
[2015-12-02 21:56:47,075][INFO ][node                     ] [node-1] started
[2015-12-02 21:56:47,123][INFO ][gateway                  ] [node-1] recovered [0] indices into cluster_state
[2015-12-02 21:56:54,298][INFO ][cluster.service          ] [node-1] added {{node-2}{cmkqC4ljRZCBD7KSAV2VsQ}{yyy.yy.yy.yyy}{yyy.yy.yy.yyy:9300},}, reason: zen-disco-join(join from node[{node-2}{cmkqC4ljRZCBD7KSAV2VsQ}{yyy.yy.yy.yyy}{yyy.yy.yy.yyy:9300}])
  </code></pre>
      <pre><code class="custom-bash">
elastic@node-2 $ cd ~/elasticsearch-2.1.0
elastic@node-2 $ bin/elasticsearch
[2015-12-02 21:56:53,118][INFO ][node                     ] [node-2] initializing ...
[2015-12-02 21:56:56,534][INFO ][node                     ] [node-2] initialized
[2015-12-02 21:56:56,543][INFO ][node                     ] [node-2] starting ...
[2015-12-02 21:56:56,738][INFO ][transport                ] [node-2] publish_address {yyy.yy.yy.yyy:9300}, bound_addresses {yyy.yy.yy.yyy:9300}
[2015-12-02 21:56:56,771][INFO ][discovery                ] [node-2] irc/cmkqC4ljRZCBD7KSAV2VsQ
[2015-12-02 21:56:59,928][INFO ][cluster.service          ] [node-2] detected_master {node-1}{dg72ivnNTxCD6K3co6tslw}{xxx.xx.xx.xx}{xxx.xx.xx.xx:9300}, added {{node-1}{dg72ivnNTxCD6K3co6tslw}{xxx.xx.xx.xx}{xxx.xx.xx.xx:9300},}, reason: zen-disco-receive(from master [{node-1}{dg72ivnNTxCD6K3co6tslw}{xxx.xx.xx.xx}{xxx.xx.xx.xx:9300}])
[2015-12-02 21:56:59,999][INFO ][http                     ] [node-2] publish_address {yyy.yy.yy.yyy:9200}, bound_addresses {yyy.yy.yy.yyy:9200}
[2015-12-02 21:56:59,999][INFO ][node                     ] [node-2] started
  </code></pre>
  <p>It's a little difficult to see via the timestamps, but <code>node-1</code> performs it's inital setup by <code>21:56:47</code>. At <code>21:56:59</code>, <code>node-2</code> detects that there is a currently running instance of <code>elasticsearch</code> that has deemed itself master. As a result, <code>node-2</code> joins the cluster.</p>
  <p>This step was really just to demonstrate the concept of a master node and other nodes joining the cluster. You can terminate both processes.</p>
  <li>Start <code>elasticsearch</code> in daemon mode and inspect the cluster.</li>
  <p>For these next steps, let's assume that my configurations are as follows:</p>
      <pre style="display:inline-block;"><code class="yaml">
cluster.name: irc
node.name: node-1
network.host: 123.456.789.100
discovery.zen.ping.unicast.hosts: ["456.789.101.234:9300"]
  </code></pre>
      <pre style="display:inline-block;"><code class="yaml">
cluster.name: irc
node.name: node-2
network.host: 456.789.101.234
discovery.zen.ping.unicast.hosts: ["123.456.789.100:9300"]
  </code></pre>
      <pre><code class="custom-bash">
elastic@node-1 $ cd ~/elasticsearch-2.1.0
elastic@node-1 $ bin/elasticsearch --daemonize
  </code></pre>
      <pre><code class="custom-bash">
elastic@node-2 $ cd ~/elasticsearch-2.1.0
elastic@node-2 $ bin/elasticsearch --daemonize
  </code></pre>
  <p>Now, both instances are started, let's see if we have a cluster.</p>
      <pre><code class="custom-bash">
elastic@node-1 $ curl 123.456.789.100:9200
{
  "name" : "node-1",
  "cluster_name" : "irc",
  "version" : {
    "number" : "2.1.0",
    "build_hash" : "72cd1f1a3eee09505e036106146dc1949dc5dc87",
    "build_timestamp" : "2015-11-18T22:40:03Z",
    "build_snapshot" : false,
    "lucene_version" : "5.3.1"
  },
  "tagline" : "You Know, for Search"
}
elastic@node-1 $ curl 123.456.789.100:9200/_cat/master
iU9QUC-LSLiEJadj2K7Ddw 123.456.789.100 123.456.789.100 node-1
elastic@node-1 $ curl 123.456.789.100:9200/_cat/nodes
456.789.101.234 456.789.101.234 2 93 0.00 d m node-2
123.456.789.100 123.456.789.100 3 94 0.00 d * node-1
elastic@node-1 $ curl 123.456.789.100:9200/_cluster/health?pretty=true
{
  "cluster_name" : "irc",
  "status" : "green",
  "timed_out" : false,
  "number_of_nodes" : 2,
  "number_of_data_nodes" : 2,
  "active_primary_shards" : 0,
  "active_shards" : 0,
  "relocating_shards" : 0,
  "initializing_shards" : 0,
  "unassigned_shards" : 0,
  "delayed_unassigned_shards" : 0,
  "number_of_pending_tasks" : 0,
  "number_of_in_flight_fetch" : 0,
  "task_max_waiting_in_queue_millis" : 0,
  "active_shards_percent_as_number" : 100.0
}
  </code></pre>
  <p>These are just some basic <code>elasticsearch</code> API calls to inspect your cluster quickly. To learn more about the powerful <code>elasticsearch</code> API, you can checkout their documentation <a class="content-link" href="https://www.elastic.co/guide/en/elasticsearch/reference/2.1/cat.html">here</a>.</p>
</ol>
<h3>Multicast</h3>
<p>Here we will discuss the multicast protocol. At the time of writing this article, the multicast protocol was decommissioned as the default in the latest available version of <code>elasticsearch</code>, <code>elasticsearch-2.1.0</code>.</p>
<p>This setup will be done on the Rackspace Cloud as we need a network that supports the multicast protocol, which the Rackspace private networks provide. You can follow these <a class="content-link" href="http://www.rackspace.com/knowledge_center/article/create-an-isolated-cloud-network-and-attach-it-to-a-server">instructions</a> to get your network set up. Next, you'll have to attach each server that will be running <code>elasticsearch</code> to this network. This, like the steps from the Rackspace article, can be done through the <a class="content-link" href="https://mycloud.rackspace.com">Rackspace Cloud Control Panel</a>:</p>
<img src="/static/img/add-cloud-network.png" style="width:50%;margin-left:25%">
<p>Assuming you have your nodes connected to a network that supports multicast, we'll proceed with the <code>elasticsearch</code> setup to support this.</p>
<ol>
  <li>Figure out what your node's private IP address is.</li>
      <pre><code class="custom-bash">
$ ifconfig eth2
eth2      Link encap:Ethernet  HWaddr bc:76:4e:21:03:3a
          inet addr:<strong style="text-decoration: underline;">192.168.3.4</strong>  Bcast:192.168.3.255  Mask:255.255.255.0
          inet6 addr: fe80::be76:4eff:fe21:33a/64 Scope:Link
          UP BROADCAST RUNNING MULTICAST  MTU:1500  Metric:1
          RX packets:803 errors:0 dropped:0 overruns:0 frame:0
          TX packets:8 errors:0 dropped:0 overruns:0 carrier:0
          collisions:0 txqueuelen:1000
          RX bytes:23705 (23.7 KB)  TX bytes:648 (648.0 B)
  </code></pre>
  <p>Our private IP is: <code>192.168.3.4</code></p>
  <li>Open up port <code>9300</code> as we did before, but make sure it is on the <code>eth2</code> interface.</li>
      <pre><code class="custom-bash">
sudo iptables -A INPUT -i eth2 -p tcp --dport 9300 -m state --state NEW,ESTABLISHED -j ACCEPT
sudo iptables -A OUTPUT -o eth2 -p tcp --sport 9300 -m state --state ESTABLISHED -j ACCEPT
  </code></pre>
  <li>Install the multicast plugin.</li>
      <pre><code class="custom-bash">
$ cd ~/elasticsearch-2.1.0
$ bin/plugin install discovery-multicast
-> Installing discovery-multicast...
Trying https://download.elastic.co/elasticsearch/release/org/elasticsearch/plugin/discovery-multicast/2.1.0/discovery-multicast-2.1.0.zip ...
Downloading ...DONE
Verifying https://download.elastic.co/elasticsearch/release/org/elasticsearch/plugin/discovery-multicast/2.1.0/discovery-multicast-2.1.0.zip checksums if available ...
Downloading .DONE
Installed discovery-multicast into /home/elastic/elasticsearch-2.1.0/plugins/discovery-multicast
  </code></pre>
  <li>Setup <code>elasticsearch.yml</code>.</li>
      <pre><code class="yaml">
cluster.name: irc
node.name: node-1
network.host: 192.168.3.4
discovery.zen.ping.multicast.enabled: true
  </code></pre>
  <li>Start <code>elasticsearch</code> and inspect our cluster.</li>
      <pre><code class="custom-bash">
elastic@node-1 $ bin/elasticsearch --daemonize
  </code></pre>
      <pre><code class="custom-bash">
elastic@node-2 $ bin/elasticsearch --daemonize
elastic@node-2 $ curl 192.168.3.5:9200/_cat/nodes
192.168.3.4 192.168.3.4 8 93 0.26 d * node-1
192.168.3.5 192.168.3.5 7 92 0.14 d m node-2
  </code></pre>
</ol>
<h2>Conclusion</h2>
<p>With that, I've demonstrated how to get Elasticsearch running utilizing the unicast protocol (now default) and the multicast protocol. There is plenty information out there on the different protocols, but this <a class="content-link" href="https://support.microsoft.com/en-us/kb/291786">article</a> from Microsoft seems to suggest to use multicast in the case that bandwidth is limited. Admittedly, I don't know enough about this topic, but one particular area in which I would think multicast proves more beneficial to unicast is when you attempt to add additional nodes to your cluster. If you found yourself in a situation where you would want to add another node, multicast does not require a configuration update and restart amongst nodes. You could simply add it to the private network, start <code>elasticsearch</code>, and it will join the cluster and begin to consume it's allocation of shards in the cluster. Using unicast, it seems as though you'd have to update the configuration of all current nodes to include your new node which would require a restart to take affect. While joins may be infrequent, they can be made less painful when using the multicast protocol.</p>
<p>I discussed earlier that using <code>elasticsearch-2.1.0</code> had cascading effects. By this I meant that ELK stack versioning can be difficult. At the time of setting up my cluster, I was using <code>elasticsearch-1.7.3</code>. When I tried to use the latest version of <a class="content-link" href="https://www.elastic.co/products/kibana">Kibana</a>, it required <code>elasticsearch-2.x.x</code>. By the time I had discovered this, <code>elasticsearch-2.1.0</code> had been released. When I finally got those agreeing with one another, I noticed that <a class="content-link" href="https://www.elastic.co/products/logstash">Logstash</a> was seemingly shipping logs, but they were not being indexed into Elasticsearch. Turns out that I needed to update my version of Logstash from <code>1.5.4</code> to <code>2.x.x</code>. My word of advice to you is that before you get started setting up your ELK stack, make sure that the versions agree with each other.</p>
<p>When I started writing my <a class="content-link" href="https://austburn.me/posts/setting_up_an_elk_stack_for_irc_logs_part_one">first post</a> I wasn't sure how many posts this endeavor would end up being. Truth is, I ran into versioning problems, there were breaking changes, and I had to adjust configuration as I went. In the next post, I will wrap up with the Logstash changes I had to make, how to get Kibana running, and potentially some more detail on some of the problems I ran into along the way. If you have any questions, feel free to ping me on <a class="content-link" href="https://twitter.com/austburn">Twitter</a>!</p>
